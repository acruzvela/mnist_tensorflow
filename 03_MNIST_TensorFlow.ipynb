{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 03_Clasificación del conjunto MNIST\n",
        "\n",
        "Vamos a completar los tutoriales anteriores con el entrenamiento de una red neuronal para tratar de resolver un problema de **clasificación multiclase**."
      ],
      "metadata": {
        "id": "cHmu_ZAlzQtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7VDGwJXbkKB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtenemos y visualizamos el dataset\n",
        "\n",
        "Obtenemos el dataset del conjunto de imágenes MINIST desde Keras.\n",
        "\n",
        "Se trata de un conjunto de imágenes de números escritos a mano del 0 al 9 dividido en dos subconjuntos:\n",
        "- Subconjunto de entrenamiento: formado por 60.000 imágenes de 28x28 píxeles.\n",
        "- Subconjunto de test: formado por 10.000 imágenes de 28x28 píxeles.\n",
        "\n",
        "Todas las imágenes son en blanco y negro, con valores en cada pixel entre 0 y 255.\n",
        "\n",
        "Hay 10 clases en las imágenes correspondientes a los números del 0 al 9.\n",
        "\n",
        "Las distribución de las clases está equilibrada en los subconjuntos de entrenamiento, con unas 6000 muestras por clase, y de test, con unas 1000 muestras por clase."
      ],
      "metadata": {
        "id": "uqxxSxNKsXHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# descargamos el dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "Z2ant0L-othH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos las dimensiones de las imágenes del subconjunto de entrenamiento\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "JNsoGKpWo234"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos las dimensiones de las etiquetas del subconjunto de entrenamiento\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "BfJPbo_Tp-7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos las dimensiones de las imágenes del subconjunto de test\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "eYDoMejDtEY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos las dimensiones de las etiquetas del subconjunto de test\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "l_pcqnxnv2CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensiones de una imagen individual\n",
        "X_train[0].shape"
      ],
      "metadata": {
        "id": "HcHLxHTXwda4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Valor máximo del pixel:', np.max(X_train[0]))\n",
        "print('Valor mínimo del pixel:', np.min(X_train[0]))"
      ],
      "metadata": {
        "id": "7Ifl22xWyr9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos los valores únicos del numpy array\n",
        "print(np.unique(y_train))"
      ],
      "metadata": {
        "id": "UEfi3f-BqU7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creamos una figura con 2 filas y 5 columnas de imágenes\n",
        "fig, axes = plt.subplots(3, 5, figsize=(12, 5))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# iteramos sobre 15 imágenes\n",
        "for i in np.arange(0, 15):\n",
        "    axes[i].imshow(X_train[i], cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {y_train[i]}\", fontsize=12)\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dqAqd6-6qXGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vemos la distribución de imágenes para cada número en el conjunto de datos de entrenamiento\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(y_train, bins=10, rwidth=0.8, color='blue', alpha=0.7)\n",
        "plt.title('Distribución de etiquetas en el conjunto de entrenamiento MNIST')\n",
        "plt.xlabel('Etiquetas')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.xticks(np.arange(0, 10))\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "whpqxs-9xjfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vemos la distribución de imágenes para cada número en el conjunto de datos de test\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(y_test, bins=10, rwidth=0.8, color='blue', alpha=0.7)\n",
        "plt.title('Distribución de etiquetas en el conjunto de test MNIST')\n",
        "plt.xlabel('Etiquetas')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.xticks(np.arange(0, 10))\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bYpOAsLarH_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformamos los datos\n",
        "\n",
        "Vamos a realizar las siguientes transformaciones en las imágenes, previamente a pasarlas por la red neuronal:\n",
        "- Pasamos las imágenes de matrices de 28x28 a vectores de longitud 784\n",
        "- Convertimos los numeros enteros de los píxeles a numeros reales\n",
        "- Normalizamos las imágenes, de manera que los valores de cada pixel pasa de estar entre 0 y 255 a estar entre 0 y 1. Para ello, dividimos los valores de la intensidad de cada pixel entre 255. Esta transnformación le va a dar estabilidad al entrenamiento de la red.\n",
        "\n",
        "Además, vamos a comprobar las dimensiones resultantes de los datasets."
      ],
      "metadata": {
        "id": "4Tq-CJHt1T1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modificamos las imágenes del subconjunto de entrenamiento\n",
        "X_train_model = X_train.reshape(60000,784).astype('float32')/255.0\n",
        "\n",
        "# modificamos las imágenes del subconjunto de test\n",
        "X_test_model = X_test.reshape(10000,784).astype('float32')/255.0\n",
        "\n",
        "print('Dimensiones de las imágenes del subconjunto de entrenamiento: ', X_train_model.shape)\n",
        "print('Dimensiones de las imágenes del subconjunto de test: ', X_test_model.shape)"
      ],
      "metadata": {
        "id": "yIh9Wypu2N2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definimos la red neuronal\n",
        "\n",
        "Como red neuronal vamos a definir una red con una entrada de un vector de 784 dimensiones en una capa densa formada por 100 neuronas con activación ReLU; tras esto le aplicamos una regularización dropout del 30% y lo pasamos a una capa densa de 50 neuronas con activación ReLU, seguida de una capa de Dropout del 30%. Finalmente tenemos una capa de salida con 10 neuronas y una activación softmax que transforma los valores de salida en probabilidades para la clasificación multiclase.\n",
        "\n",
        "Usaremos para la definición del modelo el modo Secuencial."
      ],
      "metadata": {
        "id": "Q26O6mgt0lnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# definimos el modelo de red neuronal\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "z_o1hwL2yDP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definimos el optimizador Adam\n",
        "optimizer_model = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "# definimos la función de pérdida como Spase Categorical Crossentropy\n",
        "# ya que las etiquetas de las clases nos vienen dadas como números enteros\n",
        "loss_model = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# compilamos el modelo, usando el optimizador y la pérdida definidas y como métrica la accuracy\n",
        "model.compile(optimizer=optimizer_model, loss=loss_model, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Q3YMyh-e4GMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamos el modelo con los datos de entrenamiento y de validacion\n",
        "history = model.fit(x=X_train_model,\n",
        "                    y=y_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=50,\n",
        "                    validation_data=(X_test_model, y_test))"
      ],
      "metadata": {
        "id": "V76K6mye46lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos la información del entrenamiento y la validación\n",
        "training_accuracy = history.history['accuracy']\n",
        "training_loss = history.history['loss']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "validation_loss = history.history['val_loss']\n",
        "epochs = range(1, len(training_accuracy) + 1)"
      ],
      "metadata": {
        "id": "IUdY0lvEMGSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dibujamos la evolución de la accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, training_accuracy, label='Training accuracy', color='blue')\n",
        "plt.plot(epochs, validation_accuracy, label='Validation accuracy', color='green')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# dibujamos la evolución de la pérdida\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, training_loss, label='Training loss', color='blue')\n",
        "plt.plot(epochs, validation_loss, label='Validation loss', color='green')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6u9J-JXc-DD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inferencia\n",
        "\n",
        "Con el modelo entrenado, vamos a hacer inferencia sobre algunas imágenes del subconjunto de test y visualizar si la imagen y la etiqueta se corresponde con la predicción."
      ],
      "metadata": {
        "id": "N8YHVPvb2DU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cogemos las primeras 10 imágenes del subconjunto de test\n",
        "sample_images = X_test_model[:10]"
      ],
      "metadata": {
        "id": "EdfIz3r5272I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# realizamos las predicciones con el modelo entrenado\n",
        "predicted_probs = model.predict(sample_images)\n",
        "predicted_labels = np.argmax(predicted_probs, axis=1)"
      ],
      "metadata": {
        "id": "A4qXrbcU3CFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creamos una figura con 2 filas y 5 columnas\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# iteramos sobre las 10 imágenes\n",
        "for i in np.arange(0, 10):\n",
        "    axes[i].imshow(X_test[i], cmap='gray')\n",
        "    axes[i].set_title(f\"Predicción: {predicted_labels[i]}\\nVerdadero: {y_test[i]}\", fontsize=12)\n",
        "    plt.subplots_adjust(hspace=1)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Crq00qGz3K9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PJIFV5R-viOJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}